[
    {
        "model": "Ministral-8B-Instruct-2410",
        "judge": "gpt-4o-mini",
        "task": "QA",
        "metric": "Bert Similarity Metric",
        "total_score": 18.733313199598342,
        "total_success": 2.0,
        "total_cost": 0.0,
        "total_tests": 153.0,
        "average_score": 0.12243995555293034,
        "success_rate": 0.013071895424836602
    },
    {
        "model": "Ministral-8B-Instruct-2410",
        "judge": "gpt-4o-mini",
        "task": "QA",
        "metric": "Prompt Alignment",
        "total_score": 55.0,
        "total_success": 55.0,
        "total_cost": 0.028668450000000005,
        "total_tests": 153.0,
        "average_score": 0.35947712418300654,
        "success_rate": 0.35947712418300654
    },
    {
        "model": "Ministral-8B-Instruct-2410",
        "judge": "gpt-4o-mini",
        "task": "QA",
        "metric": "Answer Relevancy",
        "total_score": 143.32103174603176,
        "total_success": 146.0,
        "total_cost": 0.04171050000000001,
        "total_tests": 153.0,
        "average_score": 0.9367387695819069,
        "success_rate": 0.954248366013072
    },
    {
        "model": "Ministral-8B-Instruct-2410",
        "judge": "gpt-4o-mini",
        "task": "QA",
        "metric": "Correctness (GEval)",
        "total_score": 36.17408833937893,
        "total_success": 0.0,
        "total_cost": 0.016062,
        "total_tests": 153.0,
        "average_score": 0.23643194993058125,
        "success_rate": 0.0
    }
]